resources:
  jobs:
    lifesciences_setup_job:
      name: "[${bundle.target}] Life Sciences - Setup Tables and Vector Search"

      tasks:
        - task_key: setup_infrastructure
          notebook_task:
            notebook_path: ../01_setup_tables_and_vector_search.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: Infrastructure

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: setup

    simple_rag_agent_deployment_job:
      name: "[${bundle.target}] Life Sciences - Deploy Simple RAG Agent"

      tasks:
        - task_key: deploy_agent
          notebook_task:
            notebook_path: ../02a_simple_rag.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: AgentDeployment

          libraries:
            - pypi:
                package: langgraph
            - pypi:
                package: databricks-agents
            - pypi:
                package: databricks-langchain
            - pypi:
                package: databricks-vectorsearch
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: deployment

    parallel_rag_agent_deployment_job:
      name: "[${bundle.target}] Life Sciences - Deploy Parallel RAG Agent"

      tasks:
        - task_key: deploy_agent
          notebook_task:
            notebook_path: ../02b_parallel_rag.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: AgentDeployment

          libraries:
            - pypi:
                package: langgraph
            - pypi:
                package: databricks-agents
            - pypi:
                package: databricks-langchain
            - pypi:
                package: databricks-vectorsearch
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: deployment

    context_for_genie_agent_deployment_job:
      name: "[${bundle.target}] Life Sciences - Deploy Context for Genie Agent"

      tasks:
        - task_key: deploy_agent
          notebook_task:
            notebook_path: ../03_context_for_genie.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}
              sql_warehouse_id: ${var.sql_warehouse_id}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: AgentDeployment

          libraries:
            - pypi:
                package: langgraph
            - pypi:
                package: databricks-agents
            - pypi:
                package: databricks-langchain
            - pypi:
                package: databricks-vectorsearch
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: deployment

    lifesciences_parallel_rag_workflow:
      name: "[${bundle.target}] Life Sciences - Parallel RAG Agent Workflow"

      tasks:
        - task_key: build_and_log_model
          notebook_task:
            notebook_path: ../02b_parallel_rag.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelBuild

          libraries:
            - pypi:
                package: langgraph
            - pypi:
                package: databricks-agents
            - pypi:
                package: databricks-langchain
            - pypi:
                package: databricks-vectorsearch
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

        - task_key: evaluate_and_promote
          depends_on:
            - task_key: build_and_log_model

          notebook_task:
            notebook_path: ../04_evaluate_and_promote.py
            base_parameters:
              model_name: ${var.catalog}.${var.schema}.lifesciences_orchestrator_agent
              catalog: ${var.catalog}
              schema: ${var.schema}
              promotion_threshold: "0.7"
              evaluation_metric: relevance

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelEvaluation

          libraries:
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

        - task_key: deploy_model
          depends_on:
            - task_key: evaluate_and_promote

          notebook_task:
            notebook_path: ../05_deploy_agent.py
            base_parameters:
              model_name: ${var.catalog}.${var.schema}.lifesciences_orchestrator_agent
              catalog: ${var.catalog}
              schema: ${var.schema}
              model_alias: champion
              endpoint_name: ""

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelDeployment

          libraries:
            - pypi:
                package: databricks-agents
            - pypi:
                package: mlflow-skinny[databricks]
            - pypi:
                package: databricks-sdk

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: workflow

    lifesciences_context_for_genie_workflow:
      name: "[${bundle.target}] Life Sciences - Context for Genie Agent Workflow"

      tasks:
        - task_key: build_and_log_model
          notebook_task:
            notebook_path: ../03_context_for_genie.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}
              sql_warehouse_id: ${var.sql_warehouse_id}

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelBuild

          libraries:
            - pypi:
                package: langgraph
            - pypi:
                package: databricks-agents
            - pypi:
                package: databricks-langchain
            - pypi:
                package: databricks-vectorsearch
            - pypi:
                package: mlflow-skinny[databricks]
            - pypi:
                package: databricks-sdk

          timeout_seconds: 3600
          max_retries: 1

        - task_key: evaluate_and_promote
          depends_on:
            - task_key: build_and_log_model

          notebook_task:
            notebook_path: ../04_evaluate_and_promote.py
            base_parameters:
              model_name: ${var.catalog}.${var.schema}.lifesciences_genie_agent
              catalog: ${var.catalog}
              schema: ${var.schema}
              promotion_threshold: "0.7"
              evaluation_metric: relevance

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelEvaluation

          libraries:
            - pypi:
                package: mlflow-skinny[databricks]

          timeout_seconds: 3600
          max_retries: 1

        - task_key: deploy_model
          depends_on:
            - task_key: evaluate_and_promote

          notebook_task:
            notebook_path: ../05_deploy_agent.py
            base_parameters:
              model_name: ${var.catalog}.${var.schema}.lifesciences_genie_agent
              catalog: ${var.catalog}
              schema: ${var.schema}
              model_alias: champion
              endpoint_name: ""

          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            data_security_mode: SINGLE_USER
            custom_tags:
              Project: LifeSciencesAgent
              Component: ModelDeployment

          libraries:
            - pypi:
                package: databricks-agents
            - pypi:
                package: mlflow-skinny[databricks]
            - pypi:
                package: databricks-sdk

          timeout_seconds: 3600
          max_retries: 1

      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}

      tags:
        environment: ${bundle.target}
        project: lifesciences_agent
        component: workflow
